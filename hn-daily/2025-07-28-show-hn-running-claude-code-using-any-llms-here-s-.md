# Show HN: Running Claude Code using any LLMs? Here's an open-source tool for it

**Posted by tensorblock on 2025-07-28**

We recently built something useful for running Claude Code with any LLMs.

Forge is an open-source API layer that allows you to combine Claude Code with any model—OpenAI, Gemini, Qwen, Moonshot, and more. It offers full flexibility without requiring changes to your existing application logic. You can mix and match models however you like.

Our demo currently runs:

- Gemini 2.5 Flash, providing a fast, lightweight option
- Qwen3-Coder-480B, offering more power for planning and code generation

But you can configure any combination that best suits your use case.

Forge provides better performance, lower costs, and full control through self-hosting options.

You can check out our quickstart repository here: [https://github.com/TensorBlock/claude-code-forge](https://github.com/TensorBlock/claude-code-forge)

We’d love to hear your thoughts!